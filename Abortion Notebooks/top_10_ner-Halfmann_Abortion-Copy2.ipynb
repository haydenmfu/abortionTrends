{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top 10 NER\n",
    "\n",
    "This sample script will create two dataframes containing the top 10 entities as well as all entities that are found in a sample of your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all our required packages\n",
    "import os\n",
    "import pandas as pd\n",
    "from lxml import etree\n",
    "from bs4 import BeautifulSoup\n",
    "import random\n",
    "\n",
    "# The spaCy library allows us to process and run operations on text\n",
    "import spacy\n",
    "from spacy.pipeline import EntityRecognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the path below with the dataset which you would like to use as input for the script\n",
    "dataset_directory = '/home/ec2-user/SageMaker/Halfmann_Abortion'\n",
    "input_files = os.listdir(dataset_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The memory usage of both processing text and the resultingdataframe can negatively impact your TDM Studio experience. For \n",
    "# this reason, we take a sample of the documents if there are too many documents in the dataset.\n",
    "#try:\n",
    "#    sample_input_files = random.sample(input_files, 1000)\n",
    "#    \n",
    "#except ValueError:\n",
    "#    sample_input_files = input_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_input_files = input_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading spacy's NLP model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "# Setting max length to be larger than default so we can process longer articles\n",
    "nlp.max_length = 15000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define a function to get the text content that we need from the XML articles available in our dataset\n",
    "def getxmlcontent(root):\n",
    "    if root.find('.//HiddenText') is not None:\n",
    "        return(root.find('.//HiddenText').text)\n",
    "    elif root.find('.//Text') is not None:\n",
    "        return(root.find('.//Text').text)\n",
    "    else:\n",
    "        print('Could not find \\\"HiddenText\\\" or \\\"Text\\\" tags')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid or missing encoding declaration for '/home/ec2-user/SageMaker/Halfmann_Abortion/data15.csv' (<string>)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<string>\"\u001b[0;36m, line \u001b[0;32munknown\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid or missing encoding declaration for '/home/ec2-user/SageMaker/Halfmann_Abortion/data15.csv'\n"
     ]
    }
   ],
   "source": [
    "# Creating empty dictionary in which to put our entities and counts\n",
    "entitydict = {}\n",
    "\n",
    "for article in sample_input_files:\n",
    "    try:\n",
    "        # Parse data and get root tags\n",
    "        tree = etree.parse(dataset_directory + \"/\" + article)\n",
    "        root = tree.getroot()\n",
    "        \n",
    "        # Clean text and remove all HTML tags\n",
    "        soup = BeautifulSoup(getxmlcontent(root))\n",
    "        text = soup.get_text()\n",
    "        \n",
    "        # Run spaCy tokenizer on doc\n",
    "        doc = nlp(text, disable=['tagger', 'parser', 'textcat'])\n",
    "        \n",
    "        # Getting entities and setting them to dict\n",
    "        for ent in doc.ents:\n",
    "#             # Uncomment this section of code if you only want one specific type of entity (e.g. PERSON)      \n",
    "#             if ent.label_ == 'PERSON':\n",
    "#                 if ent.text not in entitydict:\n",
    "#                     entitydict[ent.text] = 1\n",
    "#                 else:\n",
    "#                     entitydict[ent.text] += 1\n",
    "            \n",
    "            if ent.text not in entitydict:\n",
    "                entitydict[ent.text] = [1, ent.label_]\n",
    "            else:\n",
    "                entitydict[ent.text][0] += 1\n",
    "                \n",
    "    except TypeError:\n",
    "        print('Could not read article ' + article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the dataframes containing all entities as well as top 10 entities\n",
    "entity_df = pd.DataFrame.from_dict(entitydict, orient='index')\n",
    "top10_df = entity_df.sort_values(by=[0],ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View top 10 entities dataframe\n",
    "top10_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View dataframe of all entities (will be truncated)\n",
    "entity_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = entity_df.sort_values(by=[0],ascending=False)\n",
    "org = entities[entities[1] == \"ORG\"]\n",
    "org = org[org[0] > 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org.to_csv(\"../organizations drew.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sample_env",
   "language": "python",
   "name": "sample_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
